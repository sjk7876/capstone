Satellite Driven Parking Spot Detection & HD Map
Annotation
Badaruddin Shaikh

Dr. Fawad Ahmed

Rochester Institute of Technology
New York, USA
bs8645@rit.edu

Rochester Institute of Technology
New York, USA
fawad@cs.rit.edu

I. I NTRODUCTION
As autonomous vehicles and smart cities increasingly depend on precise HD maps, a significant gap remains—detailed
and scalable parking space data. Traditional manual annotation
methods are too slow and limited to meet the demands of
modern urban environments. This project presents an automated framework that leverages satellite imagery to detect and
annotate parking spaces at scale, bridging the precision of HD
mapping with expansive geospatial coverage. By enabling realtime updates and seamless integration, this solution not only
improves map accuracy but also supports adaptable, futureready urban mobility.

Fig. 2: Annotated Dataset Bounding Boxes + Masks

II. S YSTEM D ESIGN

Fig. 3: Axis-aligned and Non Axis-aligned Parking Space

B. Parking Space Detection
Fig. 1: System overview

III. M ETHODOLOGY
A. Data
The APKLOT [1] dataset comprises approximately 400
satellite images representing diverse parking lot environments.
Each image is annotated with both bounding boxes and
pixel-level masks, enabling flexibility across multiple training
paradigms such as object detection and semantic segmentation.
A distinguishing feature of the dataset is its annotation of
both individual and clustered parking spaces. Unlike conventional datasets, annotations are not restricted to axis-aligned
boxes; instead, they include rotated bounding boxes to better
reflect real-world parking orientations and geometric variability.
Additionally, the dataset captures a realistic distribution
of occupied and unoccupied parking spots. This variation
enables models trained on APKLOT to generalize effectively
and identify available parking spaces regardless of vehicle
presence—a critical capability for real-world deployment.

The task of parking space detection involves identifying
both individual and clustered parking spots from satellite
imagery. Several challenges complicate this task:
• Parking spots may be occupied by vehicles, making direct
detection more difficult.
• Spaces can appear as clusters or isolated units.
• Parking spots exhibit varied orientations, including both
axis-aligned and non-axis-aligned layouts.
While conventional object detection models can localize
parking areas using axis-aligned bounding boxes, this approach is often not suited for precise detection and localization. In particular, non-axis-aligned spots—common in realworld scenarios—tend to be have a loose bounding boxes,
leading to inaccurate localization and counting.
Accurately detecting and isolating individual parking spots
requires models that go beyond simple axis-aligned bounding
box predictions, accounting for geometric variability.
C. Model Choice
Initial experiments with Faster R-CNN revealed key limitations. While it was effective in detecting parking areas,

the generated bounding boxes lacked tightness, making
precise localization of individual parking spots inaccurate.
Furthermore training Faster R-CNN was also very tedious as
a single epoch required nearly 5 minutes on a 1080Ti graphics
card. Given these reasons, primarily the loose bounding boxes
for non-axis aligned bounding boxes the approach was shifted
to Mask R-CNN, which offers pixel-level segmentation,
better suited for the fine-grained nature of this task.
D. Neural Network Architecture
Fig. 5: Traning the model

Fig. 4: Neural Network Architecture
The model is a straightforward encoder–decoder built on a
pretrained ResNet backbone: we strip off the final pooling
and fully-connected layers and use everything up through
1
“layer4” to produce a 2048-channel feature map at 32
of
the input resolution. The decoder then upsamples this coarse
feature map back toward full resolution via three consecutive
ConvTranspose2d blocks—first expanding 2048 → 512
1
channels at 16
scale, then 512 → 256 at 18 , and 256 → 128
1
at 4 —each followed by a ReLU. A final 1 × 1 convolution
reduces those 128 channels to the number of segmentation
classes, and a bilinear interpolation layer restores the map
to the original 300 × 300 pixel size. The model was trained
by freezing the ResNet backbone and training only the
lightweight decoder, and with unfreezing the backbone, finetuning for this specific task. The architecture strikes a balance
between leveraging rich, pretrained features and retaining fast,
memory-efficient upsampling for dense, per-pixel prediction.
E. Model Training
The network was trained for 170 epochs using various
ResNet backbones—ResNet-50, ResNet-101, and ResNet152—to assess the impact of depth on segmentation quality.
The model seemed to perform better when the backbone was
unfrozen. The model successfully produced masks for parking
regions, these masks initially exhibited rough or jagged
edges, necessitating post-processing.
To address this, an extensive data augmentation pipeline
was implemented. This included:
• Horizontal and vertical flips to simulate different viewing angles
◦
• Random rotations (up to ±45 ) to account for varied
orientations
• Scaling and resizing to handle different zoom levels
• Random cropping to improve spatial robustness
• Noise injection to increase generalization capability
These augmentations significantly improved the quality of
the predicted masks, resulting in sharper boundaries and

Fig. 6: Mask without data augmentations
reducing the need for post-processing. This can be observed
from figure 4 and Figure 5. It is evident that that the augmentations lead to a sharper edges on the masks. Finally the model
performed best with ResNet-152 unfrozen backbone, trained
for 170 epoch along with data augmentations.
F. Post-processing and Spot Extraction
Once segmentation masks were generated by the Mask RCNN model, a post-processing pipeline was applied to detect
and isolate individual parking spots. Each mask was first
enclosed within a minimum-area rotated bounding box to
tightly capture its orientation and extent. Given that many
parking lots contain non-axis-aligned layouts, this rotationaware approach ensured a better fit than traditional axisaligned boxes.
To extract individual spots, a sliding window of dimension
of parking spot is calculated based on the zoom/scale of the
image fetched from the metadata and used as a multiplier to
the standard parking space dimension. This sliding window
was swept along the longer edge of the bounding box. Each
window was aligned such that its shorter edge lay flush against

Fig. 7: Mask with data augmentations

or non-uniform parking spot geometry, indicating areas for
future enhancement.
V. C ONCLUSION

(a) Original Image

(b) Segmentation Mask

The project successfully detected and annotated parking
spaces using satellite imagery. While the generated masks
were effective, they often required post-processing due to
their rough edges before accurate localization could be performed. Future work could explore alternative annotation
strategies—particularly those that label individual parking
spots rather than clusters—to potentially improve detection
granularity and precision.
R EFERENCES
[1] VADIVEL , M., M URUGAN , S., R AMAMOORTHY, S., A RCHANA , V.,
AND S ANKARASUBBU , M. Detecting parking spaces in a parcel using
satellite images. arXiv preprint arXiv:1909.05624 (2019).

(c) Rotated Bounding Box

(d) Extracted Parking Spots

(e) Extracted Parking Spots

Fig. 8: Visualization of the parking spot detection pipeline,
from raw image to extracted spots

the bounding box edge, preserving geometric consistency. For
a window to be considered a valid parking spot, it had to
satisfy two constraints: (1) it must lie fully within the rotated
bounding box, and (2) at least 50% of its area must overlap
with the original mask. These checks ensured both spatial
containment and meaningful alignment with the underlying
segmentation.
The result was a set of discrete, non-overlapping rectangular
boxes representing individual parking spots, even in complex
or angled layouts.
IV. R ESULTS
The Mask R-CNN model achieved an accuracy of 83%
in segmenting parking spaces. Post-processing was necessary to address jagged mask boundaries, applying edge refinement techniques to improve contour precision. Accurate
geo-localization was obtained via pixel-to-coordinate transformations, ensuring precise spatial alignment. The inference
pipeline demonstrated robustness and scalability, maintaining
consistent performance across inputs with varying resolutions.
Higher zoom-level imagery yielded finer mask granularity, directly contributing to improved segmentation accuracy. Some
degradation in performance was observed in cases of occlusion

